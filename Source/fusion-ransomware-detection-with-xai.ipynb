{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37939dc",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-29T06:46:46.573057Z",
     "iopub.status.busy": "2025-10-29T06:46:46.572819Z",
     "iopub.status.idle": "2025-10-29T06:48:03.000416Z",
     "shell.execute_reply": "2025-10-29T06:48:02.999698Z"
    },
    "papermill": {
     "duration": 76.433126,
     "end_time": "2025-10-29T06:48:03.001898",
     "exception": false,
     "start_time": "2025-10-29T06:46:46.568772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlstm==2.0.4\r\n",
      "  Downloading xlstm-2.0.4-py3-none-any.whl.metadata (24 kB)\r\n",
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (0.8.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (1.26.4)\r\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (3.4.0)\r\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (2.3.0)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (4.52.4)\r\n",
      "Collecting reportlab (from xlstm==2.0.4)\r\n",
      "  Downloading reportlab-4.4.4-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting joypy (from xlstm==2.0.4)\r\n",
      "  Downloading joypy-0.2.6-py2.py3-none-any.whl.metadata (812 bytes)\r\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (6.17.1)\r\n",
      "Requirement already satisfied: dacite in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (1.9.2)\r\n",
      "Collecting ftfy (from xlstm==2.0.4)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (1.11.1.4)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (0.33.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (14.0.0)\r\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (0.21.2)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (4.67.1)\r\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from xlstm==2.0.4) (0.12.2)\r\n",
      "Collecting mlstm_kernels (from xlstm==2.0.4)\r\n",
      "  Downloading mlstm_kernels-2.0.1-py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.12.13)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.5.1)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (7.0.0)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.0.9)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.4)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.5.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.20.1)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->xlstm==2.0.4) (0.2.13)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->xlstm==2.0.4) (3.18.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->xlstm==2.0.4) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->xlstm==2.0.4) (6.0.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->xlstm==2.0.4) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->xlstm==2.0.4) (1.1.5)\r\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->xlstm==2.0.4) (1.8.0)\r\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->xlstm==2.0.4) (7.34.0)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel->xlstm==2.0.4) (8.6.3)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->xlstm==2.0.4) (0.1.7)\r\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel->xlstm==2.0.4) (1.6.0)\r\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel->xlstm==2.0.4) (24.0.1)\r\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel->xlstm==2.0.4) (6.5.1)\r\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel->xlstm==2.0.4) (5.7.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\r\n",
      "Requirement already satisfied: scipy>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from joypy->xlstm==2.0.4) (1.15.3)\r\n",
      "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from joypy->xlstm==2.0.4) (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from joypy->xlstm==2.0.4) (3.7.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->xlstm==2.0.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->xlstm==2.0.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->xlstm==2.0.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->xlstm==2.0.4) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->xlstm==2.0.4) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->xlstm==2.0.4) (2.4.1)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf->xlstm==2.0.4) (4.9.3)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab->xlstm==2.0.4) (11.2.1)\r\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from reportlab->xlstm==2.0.4) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.6.15)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->xlstm==2.0.4) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->xlstm==2.0.4) (2.19.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->xlstm==2.0.4) (3.5)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->xlstm==2.0.4) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->xlstm==2.0.4) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->xlstm==2.0.4) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->xlstm==2.0.4)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->xlstm==2.0.4) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->xlstm==2.0.4) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->xlstm==2.0.4) (1.3.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->xlstm==2.0.4) (2024.11.6)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->xlstm==2.0.4) (0.5.3)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->xlstm==2.0.4) (75.2.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->xlstm==2.0.4) (0.19.2)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->xlstm==2.0.4) (4.4.2)\r\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->xlstm==2.0.4) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->xlstm==2.0.4) (3.0.51)\r\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->xlstm==2.0.4) (0.2.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel->xlstm==2.0.4) (4.9.0)\r\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->xlstm==2.0.4) (5.8.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel->xlstm==2.0.4) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->xlstm==2.0.4) (0.1.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->joypy->xlstm==2.0.4) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->joypy->xlstm==2.0.4) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->joypy->xlstm==2.0.4) (4.58.4)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->joypy->xlstm==2.0.4) (1.4.8)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->joypy->xlstm==2.0.4) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.20.0->joypy->xlstm==2.0.4) (2025.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xlstm==2.0.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->xlstm==2.0.4) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->xlstm==2.0.4) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->xlstm==2.0.4) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->xlstm==2.0.4) (2024.2.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->xlstm==2.0.4) (0.8.4)\r\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-client>=6.1.12->ipykernel->xlstm==2.0.4) (4.3.8)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->xlstm==2.0.4) (0.7.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->xlstm==2.0.4) (1.17.0)\r\n",
      "Downloading xlstm-2.0.4-py3-none-any.whl (91 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading joypy-0.2.6-py2.py3-none-any.whl (8.6 kB)\r\n",
      "Downloading mlstm_kernels-2.0.1-py3-none-any.whl (349 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading reportlab-4.4.4-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: reportlab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, mlstm_kernels, joypy, xlstm, torch-geometric\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "Successfully installed ftfy-6.3.1 joypy-0.2.6 mlstm_kernels-2.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 reportlab-4.4.4 torch-geometric-2.7.0 xlstm-2.0.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xlstm==2.0.4 torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74fa691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T06:48:03.050650Z",
     "iopub.status.busy": "2025-10-29T06:48:03.050422Z",
     "iopub.status.idle": "2025-10-29T06:48:19.174237Z",
     "shell.execute_reply": "2025-10-29T06:48:19.173478Z"
    },
    "papermill": {
     "duration": 16.149848,
     "end_time": "2025-10-29T06:48:19.175821",
     "exception": false,
     "start_time": "2025-10-29T06:48:03.025973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ================================\n",
    "# CELL 1 â€” Train fusion & Save .pt\n",
    "# ================================\n",
    "import os, json, csv, math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import global_mean_pool, BatchNorm, GCNConv\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# xLSTM imports\n",
    "from xlstm import (\n",
    "    xLSTMBlockStack,\n",
    "    xLSTMBlockStackConfig,\n",
    "    mLSTMBlockConfig,\n",
    "    mLSTMLayerConfig,\n",
    "    sLSTMBlockConfig,\n",
    "    sLSTMLayerConfig,\n",
    "    FeedForwardConfig\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset\n",
    "# -----------------------------\n",
    "class MultiModalDataset(Dataset):\n",
    "    CACHE_FILE = '/kaggle/input/vocab-json/vocab.json'  # náº¿u cÃ³ sáºµn vocab táº¡i input\n",
    "\n",
    "    def __init__(self, json_root, pt_root, max_seq_len=1500):\n",
    "        self.max_len = max_seq_len\n",
    "        self.samples = []\n",
    "        if os.path.isfile(self.CACHE_FILE):\n",
    "            with open(self.CACHE_FILE, 'r') as vf:\n",
    "                self.vocab = json.load(vf)\n",
    "            idx = max(self.vocab.values()) + 1\n",
    "        else:\n",
    "            self.vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "            idx = 2\n",
    "\n",
    "        mapping = [\n",
    "            (os.path.join(json_root, 'json-atb-benign-507'), os.path.join(pt_root, 'benign'), 0),\n",
    "            (os.path.join(json_root, 'ransom-5xx-new', 'ransomware'), os.path.join(pt_root, 'ransomware'), 1)\n",
    "        ]\n",
    "\n",
    "        for jdir, pdir, label in mapping:\n",
    "            if not os.path.isdir(jdir) or not os.path.isdir(pdir):\n",
    "                continue\n",
    "            for fname in os.listdir(jdir):\n",
    "                if not fname.endswith('.json'):\n",
    "                    continue\n",
    "                sid = os.path.splitext(fname)[0]\n",
    "                jpath = os.path.join(jdir, fname)\n",
    "                ppath = os.path.join(pdir, f\"{sid}.pt\")\n",
    "                if not os.path.isfile(ppath):\n",
    "                    continue\n",
    "                feat = json.load(open(jpath, 'r'))\n",
    "                toks = []\n",
    "                for call in feat.get('api_call_sequence', [])[:1000]:\n",
    "                    toks.append(f\"api:{call.get('api','')}\")\n",
    "                for ft, vals in feat.get('behavior_summary', {}).items():\n",
    "                    for v in vals:\n",
    "                        toks.append(f\"feature:{ft}:{v}\")\n",
    "                for d in feat.get('dropped_files', []):\n",
    "                    toks.append(f\"dropped_file:{d if not isinstance(d,dict) else d.get('filepath','')}\")\n",
    "                for sig in feat.get('signatures', []):\n",
    "                    toks.append(f\"signature:{sig.get('name','')}\")\n",
    "                for p in feat.get('processes', []):\n",
    "                    toks.append(f\"process:{p.get('name','')}\")\n",
    "                for proto, ents in feat.get('network', {}).items():\n",
    "                    for e in ents:\n",
    "                        if isinstance(e, dict):\n",
    "                            dst = e.get('dst') or e.get('dst_ip', '')\n",
    "                            port = e.get('dst_port') or e.get('port', '')\n",
    "                            toks.append(f\"network:{proto}:{dst}:{port}\")\n",
    "                        else:\n",
    "                            toks.append(f\"network:{proto}:{e}\")\n",
    "                if not os.path.isfile(self.CACHE_FILE):\n",
    "                    for t in toks:\n",
    "                        if t not in self.vocab:\n",
    "                            self.vocab[t] = idx; idx += 1\n",
    "                self.samples.append((ppath, toks, label))\n",
    "        if not os.path.isfile(self.CACHE_FILE):\n",
    "            json.dump(self.vocab, open(self.CACHE_FILE, 'w'), ensure_ascii=False, indent=2)\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ppath, toks, label = self.samples[i]\n",
    "        data = torch.load(ppath, weights_only=False)\n",
    "        idxs = [self.vocab.get(t, self.vocab['<UNK>']) for t in toks]\n",
    "        if len(idxs) < self.max_len:\n",
    "            idxs += [self.vocab['<PAD>']] * (self.max_len - len(idxs))\n",
    "        else:\n",
    "            idxs = idxs[:self.max_len]\n",
    "        return data, torch.tensor(idxs), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    gs, seqs, labels = zip(*batch)\n",
    "    return Batch.from_data_list(gs), torch.stack(seqs), torch.stack(labels)\n",
    "\n",
    "# -----------------------------\n",
    "# Models\n",
    "# -----------------------------\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_feats, hidden=64, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_feats, hidden)\n",
    "        self.bn1 = BatchNorm(hidden)\n",
    "        self.conv2 = GCNConv(hidden, hidden)\n",
    "        self.bn2 = BatchNorm(hidden)\n",
    "        self.drop = drop\n",
    "        self.output_dim = hidden\n",
    "\n",
    "    def forward(self, x, ei, b):\n",
    "        x = F.relu(self.bn1(self.conv1(x, ei)))\n",
    "        x = F.dropout(x, self.drop, training=self.training)\n",
    "        x = F.relu(self.bn2(self.conv2(x, ei)))\n",
    "        x = F.dropout(x, self.drop, training=self.training)\n",
    "        return global_mean_pool(x, b)\n",
    "\n",
    "class xLSTMEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed=128, seq_len=1500, blocks=1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed, padding_idx=0)\n",
    "        cfg = xLSTMBlockStackConfig(\n",
    "            mlstm_block=mLSTMBlockConfig(mlstm=mLSTMLayerConfig(conv1d_kernel_size=4, qkv_proj_blocksize=4, num_heads=4)),\n",
    "            slstm_block=sLSTMBlockConfig(slstm=sLSTMLayerConfig(backend=\"vanilla\", num_heads=4, conv1d_kernel_size=4,\n",
    "                                                                bias_init=\"powerlaw_blockdependent\"),\n",
    "            feedforward=FeedForwardConfig(proj_factor=1.3, act_fn=\"gelu\"),),\n",
    "            context_length=seq_len, num_blocks=blocks, embedding_dim=embed, slstm_at=[0]\n",
    "        )\n",
    "        self.xlstm = xLSTMBlockStack(cfg)\n",
    "        self.output_dim = embed\n",
    "\n",
    "    def forward(self, seq):\n",
    "        return self.xlstm(self.embed(seq)).mean(dim=1)\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.fc(x).squeeze(1)\n",
    "\n",
    "class MultiModalClassifier(nn.Module):\n",
    "    def __init__(self, graph_enc, seq_enc, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.gcn = graph_enc\n",
    "        self.xlstm = seq_enc\n",
    "        fusion_dim = graph_enc.output_dim + seq_enc.output_dim\n",
    "        self.classifier = MLPClassifier(fusion_dim, drop=drop)\n",
    "    def forward(self, g, seq, return_emb=False):\n",
    "        g_emb = self.gcn(g.x, g.edge_index, g.batch)\n",
    "        s_emb = self.xlstm(seq)\n",
    "        fused = torch.cat([g_emb, s_emb], dim=1)\n",
    "        logit = self.classifier(fused)\n",
    "        if return_emb:\n",
    "            return logit, g_emb, s_emb, fused\n",
    "        return logit\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics & Train\n",
    "# -----------------------------\n",
    "def eval_met(m, l, c, d):\n",
    "    m.eval(); ls, allp, alll = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for g, seq, labs in l:\n",
    "            g, seq, labs = g.to(d), seq.to(d), labs.to(d)\n",
    "            logits = m(g, seq)\n",
    "            ls += c(logits, labs).item() * labs.size(0)\n",
    "            p = (torch.sigmoid(logits) > 0.5).float()\n",
    "            allp.extend([int(x) for x in p.cpu().tolist()])\n",
    "            alll.extend([int(x) for x in labs.cpu().tolist()])\n",
    "    cm = confusion_matrix(alll, allp, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    t = tp + tn + fp + fn\n",
    "    return {'loss': ls/max(t,1), 'acc': (tp+tn)/max(t,1),\n",
    "            'tpr': tp/(tp+fn+1e-9), 'fpr': fp/(fp+tn+1e-9),\n",
    "            'f1': f1_score(alll, allp, zero_division=0)}\n",
    "\n",
    "def run_training_fusion(model, ds, device, tag='GCN+xLSTM'):\n",
    "    lbls = [lbl for _, _, lbl in ds.samples]\n",
    "    outer = StratifiedShuffleSplit(n_splits=1, test_size=0.15, random_state=42)\n",
    "    tv, te = next(outer.split(range(len(ds)), lbls))\n",
    "    inner = StratifiedShuffleSplit(n_splits=1, test_size=0.17647, random_state=42)\n",
    "    tr_rel, val_rel = next(inner.split(tv, [lbls[i] for i in tv]))\n",
    "    tr = [tv[i] for i in tr_rel]; val = [tv[i] for i in val_rel]\n",
    "\n",
    "    tr_ld = DataLoader(Subset(ds, tr), 8, shuffle=True, collate_fn=collate_fn)\n",
    "    val_ld = DataLoader(Subset(ds, val), 8, shuffle=False, collate_fn=collate_fn)\n",
    "    te_ld  = DataLoader(Subset(ds, te), 8, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    crit = nn.BCEWithLogitsLoss()\n",
    "    opt  = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    best_f1, patience, no_imp = 0, 5, 0\n",
    "    for ep in range(1, 21):\n",
    "        model.train(); ls, cor, tot = 0, 0, 0\n",
    "        for g, seq, labs in tr_ld:\n",
    "            g, seq, labs = g.to(device), seq.to(device), labs.to(device)\n",
    "            opt.zero_grad()\n",
    "            logits = model(g, seq)\n",
    "            loss = crit(logits, labs)\n",
    "            loss.backward(); opt.step()\n",
    "            ls += loss.item()*labs.size(0)\n",
    "            pred = (torch.sigmoid(logits)>0.5).float()\n",
    "            cor += (pred==labs).sum().item(); tot += labs.size(0)\n",
    "        trl, tra = ls/max(tot,1), cor/max(tot,1)\n",
    "        vm = eval_met(model, val_ld, crit, device)\n",
    "        print(f\"[{tag}] Epoch {ep:02d} | Train Loss: {trl:.4f}, Acc: {tra:.4f} | \"\n",
    "              f\"Val Loss: {vm['loss']:.4f}, Acc: {vm['acc']:.4f}, F1: {vm['f1']:.4f}\")\n",
    "        if vm['f1'] > best_f1:\n",
    "            best_f1, o_val = vm['f1'], model.state_dict(); no_imp = 0\n",
    "        else:\n",
    "            no_imp += 1\n",
    "        if no_imp >= patience:\n",
    "            print(f\"[{tag}] Early stopping at epoch {ep}\"); break\n",
    "\n",
    "    model.load_state_dict(o_val)\n",
    "    tm = eval_met(model, te_ld, crit, device)\n",
    "    print(f\"[{tag}] Test Loss: {tm['loss']:.4f}, Acc: {tm['acc']:.4f}, \"\n",
    "          f\"TPR: {tm['tpr']:.4f}, FPR: {tm['fpr']:.4f}, F1: {tm['f1']:.4f}\")\n",
    "    return tr_ld, val_ld, te_ld\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d694203f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T06:48:19.224166Z",
     "iopub.status.busy": "2025-10-29T06:48:19.223790Z",
     "iopub.status.idle": "2025-10-29T06:48:19.227994Z",
     "shell.execute_reply": "2025-10-29T06:48:19.227326Z"
    },
    "papermill": {
     "duration": 0.029383,
     "end_time": "2025-10-29T06:48:19.229144",
     "exception": false,
     "start_time": "2025-10-29T06:48:19.199761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# CELL 2 â€” Inference + XAI (per-sample) â€” CORRECTED\n",
    "# =====================================\n",
    "import os, json, csv, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import global_mean_pool, BatchNorm, GCNConv\n",
    "from torch_geometric.explain import Explainer, GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55d3172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T06:48:19.276079Z",
     "iopub.status.busy": "2025-10-29T06:48:19.275842Z",
     "iopub.status.idle": "2025-10-29T06:48:19.293989Z",
     "shell.execute_reply": "2025-10-29T06:48:19.293319Z"
    },
    "papermill": {
     "duration": 0.042692,
     "end_time": "2025-10-29T06:48:19.295116",
     "exception": false,
     "start_time": "2025-10-29T06:48:19.252424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======= (re)Define Dataset & Models =======\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, json_root, pt_root, max_seq_len=1500, vocab_json=None):\n",
    "        self.max_len = max_seq_len\n",
    "        self.samples = []\n",
    "        if vocab_json and os.path.isfile(vocab_json):\n",
    "            with open(vocab_json, 'r') as vf:\n",
    "                self.vocab = json.load(vf)\n",
    "        else:\n",
    "            default_cache = '/kaggle/input/vocab-json/vocab.json'\n",
    "            if os.path.isfile(default_cache):\n",
    "                self.vocab = json.load(open(default_cache,'r'))\n",
    "            else:\n",
    "                raise FileNotFoundError(\"No vocab found. Provide vocab_runtime.json or /kaggle/input/vocab-json/vocab.json\")\n",
    "\n",
    "        mapping = [\n",
    "            (os.path.join(json_root, 'json-atb-benign-507'), os.path.join(pt_root, 'benign'), 0),\n",
    "            (os.path.join(json_root, 'ransom-5xx-new', 'ransomware'), os.path.join(pt_root, 'ransomware'), 1)\n",
    "        ]\n",
    "        for jdir, pdir, label in mapping:\n",
    "            if not os.path.isdir(jdir) or not os.path.isdir(pdir): continue\n",
    "            for fname in os.listdir(jdir):\n",
    "                if not fname.endswith('.json'): continue\n",
    "                sid = os.path.splitext(fname)[0]\n",
    "                jpath = os.path.join(jdir, fname)\n",
    "                ppath = os.path.join(pdir, f\"{sid}.pt\")\n",
    "                if not os.path.isfile(ppath): continue\n",
    "                feat = json.load(open(jpath,'r'))\n",
    "                toks = []\n",
    "                for call in feat.get('api_call_sequence', [])[:1000]:\n",
    "                    toks.append(f\"api:{call.get('api','')}\")\n",
    "                for ft, vals in feat.get('behavior_summary', {}).items():\n",
    "                    for v in vals: toks.append(f\"feature:{ft}:{v}\")\n",
    "                for d in feat.get('dropped_files', []):\n",
    "                    toks.append(f\"dropped_file:{d if not isinstance(d,dict) else d.get('filepath','')}\")\n",
    "                for sig in feat.get('signatures', []):\n",
    "                    toks.append(f\"signature:{sig.get('name','')}\")\n",
    "                for p in feat.get('processes', []):\n",
    "                    toks.append(f\"process:{p.get('name','')}\")\n",
    "                for proto, ents in feat.get('network', {}).items():\n",
    "                    for e in ents:\n",
    "                        if isinstance(e, dict):\n",
    "                            dst = e.get('dst') or e.get('dst_ip','')\n",
    "                            port = e.get('dst_port') or e.get('port','')\n",
    "                            toks.append(f\"network:{proto}:{dst}:{port}\")\n",
    "                        else: toks.append(f\"network:{proto}:{e}\")\n",
    "                self.samples.append((ppath, toks, label))\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, i):\n",
    "        ppath, toks, label = self.samples[i]\n",
    "        data = torch.load(ppath, weights_only=False)\n",
    "        idxs = [self.vocab.get(t, self.vocab['<UNK>']) for t in toks]\n",
    "        if len(idxs) < self.max_len:\n",
    "            idxs += [self.vocab['<PAD>']] * (self.max_len - len(idxs))\n",
    "        else:\n",
    "            idxs = idxs[:self.max_len]\n",
    "        return data, torch.tensor(idxs), torch.tensor(int(label), dtype=torch.float32)\n",
    "\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_feats, hidden=64, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_feats, hidden)\n",
    "        self.bn1 = BatchNorm(hidden)\n",
    "        self.conv2 = GCNConv(hidden, hidden)\n",
    "        self.bn2 = BatchNorm(hidden)\n",
    "        self.drop = drop\n",
    "        self.output_dim = hidden\n",
    "    def forward(self, x, ei, b):\n",
    "        x = F.relu(self.bn1(self.conv1(x, ei)))\n",
    "        x = F.dropout(x, self.drop, training=self.training)\n",
    "        x = F.relu(self.bn2(self.conv2(x, ei)))\n",
    "        x = F.dropout(x, self.drop, training=self.training)\n",
    "        return global_mean_pool(x, b)\n",
    "\n",
    "class xLSTMEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed=128, seq_len=1500, blocks=1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed, padding_idx=0)\n",
    "        cfg = xLSTMBlockStackConfig(\n",
    "        mlstm_block=mLSTMBlockConfig(\n",
    "            mlstm=mLSTMLayerConfig(conv1d_kernel_size=4, qkv_proj_blocksize=4, num_heads=4)\n",
    "        ),\n",
    "        slstm_block=sLSTMBlockConfig(\n",
    "            slstm=sLSTMLayerConfig(\n",
    "                backend=\"vanilla\",\n",
    "                num_heads=4,\n",
    "                conv1d_kernel_size=4,\n",
    "                bias_init=\"powerlaw_blockdependent\",\n",
    "            ),\n",
    "            feedforward=FeedForwardConfig(proj_factor=1.3, act_fn=\"gelu\"), \n",
    "        ),\n",
    "        context_length=seq_len,\n",
    "        num_blocks=blocks,\n",
    "        embedding_dim=embed,\n",
    "        slstm_at=[0],\n",
    "    )\n",
    "\n",
    "        from xlstm import xLSTMBlockStack\n",
    "        self.xlstm = xLSTMBlockStack(cfg)\n",
    "        self.output_dim = embed\n",
    "    def forward(self, seq):\n",
    "        return self.xlstm(self.embed(seq)).mean(dim=1)\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(drop),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x): return self.fc(x).squeeze(1)\n",
    "\n",
    "class MultiModalClassifier(nn.Module):\n",
    "    def __init__(self, graph_enc, seq_enc, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.gcn = graph_enc\n",
    "        self.xlstm = seq_enc\n",
    "        fusion_dim = graph_enc.output_dim + seq_enc.output_dim\n",
    "        self.classifier = MLPClassifier(fusion_dim, drop=drop)\n",
    "    def forward(self, g, seq, return_emb=False):\n",
    "        g_emb = self.gcn(g.x, g.edge_index, g.batch)\n",
    "        s_emb = self.xlstm(seq)\n",
    "        fused = torch.cat([g_emb, s_emb], dim=1)\n",
    "        logit = self.classifier(fused)\n",
    "        if return_emb:\n",
    "            return logit, g_emb, s_emb, fused\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abb78af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-29T06:48:19.342698Z",
     "iopub.status.busy": "2025-10-29T06:48:19.342414Z",
     "iopub.status.idle": "2025-10-29T07:06:03.984787Z",
     "shell.execute_reply": "2025-10-29T07:06:03.984086Z"
    },
    "papermill": {
     "duration": 1064.691509,
     "end_time": "2025-10-29T07:06:04.009969",
     "exception": false,
     "start_time": "2025-10-29T06:48:19.318460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /kaggle/input/fusion-pt/fusion_model.pt\n",
      "[Inference] index=2, label=0, prob=0.5348, pred=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:180.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[XAI-L1] graph_score=14.459 | seq_score=14.824 | dominant=seq\n",
      "[SAVE] /kaggle/working/single_sample_branch.csv\n",
      "[XAI-L2 Graph] top_nodes=[1570, 1540, 1566, 1569, 1541] | top_edges_idx=[2383, 2379, 2381, 2450, 2449]\n",
      "=== TOP NODES ANALYSIS ===\n",
      "Node 1570: Degree=68, Features: Feature dim: 768, Mean: -0.008\n",
      "Node 1540: Degree=857, Features: Feature dim: 768, Mean: -0.009\n",
      "Node 1566: Degree=2, Features: Feature dim: 768, Mean: -0.008\n",
      "Node 1569: Degree=2, Features: Feature dim: 768, Mean: -0.008\n",
      "Node 1541: Degree=144, Features: Feature dim: 768, Mean: -0.009\n",
      "\n",
      "=== TOP EDGES ANALYSIS ===\n",
      "Edge 2383: 1570 â†’ 1540\n",
      "Edge 2379: 1566 â†’ 1540\n",
      "Edge 2381: 1569 â†’ 1540\n",
      "Edge 2450: 1570 â†’ 1541\n",
      "Edge 2449: 1570 â†’ 1340\n",
      "\n",
      "=== GRAPH PATTERN INTERPRETATION ===\n",
      "ğŸ”— HUB NODES (high connectivity): [1570, 1540, 1541]\n",
      "   â†’ CÃ¡c node nÃ y cÃ³ thá»ƒ lÃ  processes chÃ­nh hoáº·c critical system resources\n",
      "ğŸ”´ CRITICAL CONNECTIONS between top nodes: [(1570, 1540), (1566, 1540), (1569, 1540), (1570, 1541)]\n",
      "   â†’ ÄÃ¢y lÃ  cÃ¡c káº¿t ná»‘i quan trá»ng nháº¥t trong Ä‘á»“ thá»‹\n",
      "â­ STAR PATTERN NODES: [1570]\n",
      "   â†’ CÃ¡c node nÃ y káº¿t ná»‘i vá»›i nhiá»u node khÃ¡c, cÃ³ thá»ƒ lÃ  central processes\n",
      "[XAI-L2 Seq] top_tokens (preview 10): api:GetSystemTimeAsFileTime:0.403, api:NtOpenKey:0.372, feature:regkey_read:HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Fusion\\NativeImagesIndex\\v2.0.50727_64\\IL\\7950e2c5\\19b8f67f\\82\\DisplayName:0.329, api:GetSystemTimeAsFileTime:0.324, feature:file_opened:C:\\:0.322, feature:file_failed:C:\\Windows\\Microsoft.NET\\Framework64\\Upgrades.2.0.50727\\:0.302, feature:regkey_read:HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion\\MiniDumpAuxiliaryDlls\\C:\\Windows\\system32\\RPCRT4.dll:0.302, feature:file_opened:C:\\Windows\\Microsoft.NET\\Framework64\\v2.0.50727\\:0.298, api:NtSetInformationFile:0.291, api:NtQueryValueKey:0.284\n",
      "[SAVE] /kaggle/working/single_sample_sequence_tokens.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'index': 2,\n",
       " 'label': 0,\n",
       " 'prob': 0.5348159670829773,\n",
       " 'pred': 1,\n",
       " 'branch': {'graph_score': 14.458660125732422,\n",
       "  'seq_score': 14.823923110961914,\n",
       "  'dominant': 'seq'},\n",
       " 'graph_top_nodes': [1570, 1540, 1566, 1569, 1541],\n",
       " 'graph_top_edges_idx': [2383, 2379, 2381, 2450, 2449],\n",
       " 'seq_top_tokens': [('api:GetSystemTimeAsFileTime', 0.4028666019439697),\n",
       "  ('api:NtOpenKey', 0.372043251991272),\n",
       "  ('feature:regkey_read:HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Fusion\\\\NativeImagesIndex\\\\v2.0.50727_64\\\\IL\\\\7950e2c5\\\\19b8f67f\\\\82\\\\DisplayName',\n",
       "   0.3290649652481079),\n",
       "  ('api:GetSystemTimeAsFileTime', 0.32440558075904846),\n",
       "  ('feature:file_opened:C:\\\\', 0.3222436308860779),\n",
       "  ('feature:file_failed:C:\\\\Windows\\\\Microsoft.NET\\\\Framework64\\\\Upgrades.2.0.50727\\\\',\n",
       "   0.30211156606674194),\n",
       "  ('feature:regkey_read:HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows NT\\\\CurrentVersion\\\\MiniDumpAuxiliaryDlls\\\\C:\\\\Windows\\\\system32\\\\RPCRT4.dll',\n",
       "   0.30157166719436646),\n",
       "  ('feature:file_opened:C:\\\\Windows\\\\Microsoft.NET\\\\Framework64\\\\v2.0.50727\\\\',\n",
       "   0.297972708940506),\n",
       "  ('api:NtSetInformationFile', 0.29113441705703735),\n",
       "  ('api:NtQueryValueKey', 0.2835623323917389),\n",
       "  ('feature:regkey_read:HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\ControlSet001\\\\Control\\\\Keyboard Layouts\\\\00010445\\\\layout id',\n",
       "   0.27908557653427124),\n",
       "  ('feature:regkey_read:HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Windows\\\\CurrentVersion\\\\Internet Settings\\\\WinHttp\\\\DisableBranchCache',\n",
       "   0.27660930156707764),\n",
       "  ('feature:regkey_read:HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\Fusion\\\\NativeImagesIndex\\\\v2.0.50727_64\\\\NI\\\\181938c6\\\\7950e2c5\\\\82\\\\ILDependencies',\n",
       "   0.2729532718658447),\n",
       "  ('feature:regkey_read:HKEY_LOCAL_MACHINE\\\\SYSTEM\\\\ControlSet001\\\\Control\\\\Keyboard Layouts\\\\00020408\\\\layout id',\n",
       "   0.2710497975349426),\n",
       "  ('feature:file_exists:C:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Temp\\\\Transparent.Orchestration.Trap.exe',\n",
       "   0.26602792739868164),\n",
       "  ('feature:regkey_read:HKEY_LOCAL_MACHINE\\\\SOFTWARE\\\\Microsoft\\\\.NETFramework\\\\TURNOFFDEBUGINFO',\n",
       "   0.2658763825893402),\n",
       "  ('feature:file_exists:C:\\\\Windows\\\\Microsoft.NET\\\\Framework64\\\\v2.0.50727\\\\mscorwks.dll',\n",
       "   0.26546716690063477),\n",
       "  ('feature:regkey_opened:HKEY_CURRENT_USER\\\\Software\\\\Microsoft\\\\Windows\\\\Windows Error Reporting',\n",
       "   0.2645774781703949),\n",
       "  ('feature:file_exists:C:\\\\Windows\\\\System32\\\\shell32.dll',\n",
       "   0.2605133354663849),\n",
       "  ('feature:regkey_opened:HKEY_LOCAL_MACHINE\\\\Software\\\\Microsoft\\\\Windows\\\\Windows Error Reporting\\\\HeapControlledList\\\\661.exe',\n",
       "   0.25927281379699707)]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- helpers ----------\n",
    "def get_index_by_sid(ds, sid: str):\n",
    "    target = f\"{sid}.pt\"\n",
    "    for i, (ppath, _, _) in enumerate(ds.samples):\n",
    "        if ppath.endswith(target):\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def make_single_batch(ds, index: int, device):\n",
    "    data, seq, label = ds[index]\n",
    "    g = Batch.from_data_list([data]).to(device)\n",
    "    seq = seq.unsqueeze(0).to(device)\n",
    "    return g, seq, int(label.item())\n",
    "\n",
    "@torch.no_grad()\n",
    "def _get_embeddings(model, g, seq):\n",
    "    model.eval()\n",
    "    logits, g_emb, s_emb, fused = model(g, seq, return_emb=True)\n",
    "    return logits, g_emb.detach(), s_emb.detach(), fused.detach()\n",
    "\n",
    "def integrated_gradients_fused(model, g, seq, device, steps=64, baseline='zero'):\n",
    "    model.eval()\n",
    "    _, g_emb, s_emb, fused = _get_embeddings(model, g, seq)\n",
    "    if baseline == 'zero':\n",
    "        base = torch.zeros_like(fused)\n",
    "    elif baseline == 'mean':\n",
    "        base = fused.mean(dim=0, keepdim=True).repeat(fused.size(0), 1)\n",
    "    else:\n",
    "        base = torch.zeros_like(fused)\n",
    "    total_attr = torch.zeros_like(fused)\n",
    "    for alpha in torch.linspace(0, 1, steps, device=device):\n",
    "        x = base + alpha * (fused - base)\n",
    "        x.requires_grad_(True)\n",
    "        logits = model.classifier(x)\n",
    "        grads = torch.autograd.grad(logits.sum(), x, retain_graph=False)[0]\n",
    "        total_attr += grads\n",
    "    ig = (fused - base) * (total_attr / steps)\n",
    "    return ig, fused, g_emb, s_emb\n",
    "\n",
    "def branch_scores_from_ig(ig, g_dim):\n",
    "    g_attr = ig[:, :g_dim]\n",
    "    s_attr = ig[:, g_dim:]\n",
    "    g_score = g_attr.abs().sum(dim=1)\n",
    "    s_score = s_attr.abs().sum(dim=1)\n",
    "    return g_score, s_score\n",
    "\n",
    "\n",
    "\n",
    "def explain_graph_simple(model, data_single, device, topk=5):\n",
    "    \"\"\"Simplified graph explanation using gradient-based importance\"\"\"\n",
    "    data_single = data_single.to(device)\n",
    "    data_single.x.requires_grad_(True)\n",
    "    \n",
    "    # Forward pass\n",
    "    graph_emb = model.gcn(data_single.x, data_single.edge_index, data_single.batch)\n",
    "    \n",
    "    # Use only graph part of the classifier for attribution\n",
    "    with torch.no_grad():\n",
    "        fc0 = model.classifier.fc[0]\n",
    "        W_left = fc0.weight[:, :model.gcn.output_dim].mean(dim=0, keepdim=True).T\n",
    "    \n",
    "    score = (graph_emb @ W_left).sum()\n",
    "    \n",
    "    # Compute gradients\n",
    "    score.backward()\n",
    "    \n",
    "    # Node importance based on gradient magnitude\n",
    "    node_imp = data_single.x.grad.abs().sum(dim=1)\n",
    "    \n",
    "    # For edge importance, we can use a simple heuristic based on connected nodes\n",
    "    edge_imp = torch.zeros(data_single.edge_index.size(1), device=device)\n",
    "    for i, (src, dst) in enumerate(data_single.edge_index.t()):\n",
    "        edge_imp[i] = (node_imp[src] + node_imp[dst]) / 2\n",
    "    \n",
    "    node_imp = node_imp.detach().cpu()\n",
    "    edge_imp = edge_imp.detach().cpu()\n",
    "    \n",
    "    k_nodes = min(topk, node_imp.numel())\n",
    "    k_edges = min(topk, edge_imp.numel())\n",
    "    top_nodes = node_imp.topk(k_nodes).indices.tolist()\n",
    "    top_edges = edge_imp.topk(k_edges).indices.tolist()\n",
    "    \n",
    "    return top_nodes, top_edges, node_imp, edge_imp\n",
    "\n",
    "def explain_sequence_single(model, seq_batch, device, ds, topk=20, steps=64):\n",
    "    emb_layer = model.xlstm.embed\n",
    "    with torch.no_grad():\n",
    "        emb = emb_layer(seq_batch).detach()\n",
    "    base = torch.zeros_like(emb)\n",
    "    total_attr = torch.zeros_like(emb)\n",
    "    for alpha in torch.linspace(0, 1, steps, device=device):\n",
    "        x = base + alpha * (emb - base)\n",
    "        x.requires_grad_(True)\n",
    "        s_out = model.xlstm.xlstm(x)\n",
    "        s_pooled = s_out.mean(dim=1)\n",
    "        g_zero = torch.zeros(s_pooled.size(0), model.gcn.output_dim, device=device)\n",
    "        fused_ = torch.cat([g_zero, s_pooled], dim=1)\n",
    "        logit_ = model.classifier(fused_)\n",
    "        grads = torch.autograd.grad(logit_.sum(), x, retain_graph=False)[0]\n",
    "        total_attr += grads\n",
    "    ig = (emb - base) * (total_attr / steps)\n",
    "    token_scores = ig.abs().sum(dim=2).squeeze(0)  # [T]\n",
    "    \n",
    "    # Move everything to CPU for indexing\n",
    "    token_scores = token_scores.cpu()\n",
    "    pad_id = ds.vocab['<PAD>']\n",
    "    id2tok = {v: k for k, v in ds.vocab.items()}\n",
    "    tokens = seq_batch.squeeze(0).detach().cpu()\n",
    "    valid = (tokens != pad_id).nonzero(as_tuple=False).view(-1)\n",
    "    \n",
    "    if valid.numel() == 0:\n",
    "        return []\n",
    "    \n",
    "    k = min(topk, valid.numel())\n",
    "    top = token_scores[valid].topk(k)\n",
    "    sel_idx = valid[top.indices.cpu()].tolist()  # Ensure indices are on CPU\n",
    "    \n",
    "    return [(id2tok.get(int(tokens[i]), str(int(tokens[i]))), float(token_scores[i].item())) for i in sel_idx]\n",
    "\n",
    "def analyze_graph_structure(data_single, top_nodes, top_edges, save_path='/kaggle/working/graph_analysis.csv'):\n",
    "    \"\"\"PhÃ¢n tÃ­ch chi tiáº¿t cáº¥u trÃºc Ä‘á»“ thá»‹ cho cÃ¡c node vÃ  edge quan trá»ng\"\"\"\n",
    "    analysis = []\n",
    "    \n",
    "    # PhÃ¢n tÃ­ch top nodes\n",
    "    print(\"=== TOP NODES ANALYSIS ===\")\n",
    "    for i, node_idx in enumerate(top_nodes, 1):\n",
    "        if node_idx < data_single.x.size(0):\n",
    "            node_features = data_single.x[node_idx]\n",
    "            analysis.append({\n",
    "                'type': 'node',\n",
    "                'rank': i,\n",
    "                'node_id': node_idx,\n",
    "                'feature_summary': f\"Feature dim: {node_features.size(0)}, Mean: {node_features.mean().item():.3f}\",\n",
    "                'degree': (data_single.edge_index[0] == node_idx).sum().item()  # Sá»‘ káº¿t ná»‘i\n",
    "            })\n",
    "            print(f\"Node {node_idx}: Degree={analysis[-1]['degree']}, Features: {analysis[-1]['feature_summary']}\")\n",
    "    \n",
    "    # PhÃ¢n tÃ­ch top edges\n",
    "    print(\"\\n=== TOP EDGES ANALYSIS ===\")\n",
    "    for i, edge_idx in enumerate(top_edges, 1):\n",
    "        if edge_idx < data_single.edge_index.size(1):\n",
    "            src_node = data_single.edge_index[0, edge_idx].item()\n",
    "            dst_node = data_single.edge_index[1, edge_idx].item()\n",
    "            analysis.append({\n",
    "                'type': 'edge', \n",
    "                'rank': i,\n",
    "                'edge_id': edge_idx,\n",
    "                'source_node': src_node,\n",
    "                'target_node': dst_node,\n",
    "                'connection': f\"{src_node} -> {dst_node}\"\n",
    "            })\n",
    "            print(f\"Edge {edge_idx}: {src_node} â†’ {dst_node}\")\n",
    "    \n",
    "    # LÆ°u káº¿t quáº£\n",
    "    import csv\n",
    "    with open(save_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=['type', 'rank', 'node_id', 'feature_summary', 'degree', 'edge_id', 'source_node', 'target_node', 'connection'])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(analysis)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def interpret_graph_patterns(analysis, top_nodes, top_edges):\n",
    "    \"\"\"Diá»…n giáº£i cÃ¡c máº«u Ä‘á»“ thá»‹ quan trá»ng\"\"\"\n",
    "    print(\"\\n=== GRAPH PATTERN INTERPRETATION ===\")\n",
    "    \n",
    "    # TÃ¬m cÃ¡c node cÃ³ nhiá»u káº¿t ná»‘i (hub nodes)\n",
    "    hub_nodes = [item for item in analysis if item['type'] == 'node' and item['degree'] > 10]\n",
    "    if hub_nodes:\n",
    "        print(f\"ğŸ”— HUB NODES (high connectivity): {[n['node_id'] for n in hub_nodes]}\")\n",
    "        print(\"   â†’ CÃ¡c node nÃ y cÃ³ thá»ƒ lÃ  processes chÃ­nh hoáº·c critical system resources\")\n",
    "    \n",
    "    # PhÃ¢n tÃ­ch cÃ¡c káº¿t ná»‘i quan trá»ng\n",
    "    critical_edges = []\n",
    "    for edge_info in [item for item in analysis if item['type'] == 'edge']:\n",
    "        src, dst = edge_info['source_node'], edge_info['target_node']\n",
    "        # Kiá»ƒm tra náº¿u káº¿t ná»‘i giá»¯a cÃ¡c top nodes\n",
    "        if src in top_nodes and dst in top_nodes:\n",
    "            critical_edges.append((src, dst))\n",
    "    \n",
    "    if critical_edges:\n",
    "        print(f\"ğŸ”´ CRITICAL CONNECTIONS between top nodes: {critical_edges}\")\n",
    "        print(\"   â†’ ÄÃ¢y lÃ  cÃ¡c káº¿t ná»‘i quan trá»ng nháº¥t trong Ä‘á»“ thá»‹\")\n",
    "    \n",
    "    # TÃ¬m star patterns (má»™t node káº¿t ná»‘i vá»›i nhiá»u node khÃ¡c)\n",
    "    from collections import defaultdict\n",
    "    connection_count = defaultdict(int)\n",
    "    for edge_info in [item for item in analysis if item['type'] == 'edge']:\n",
    "        connection_count[edge_info['source_node']] += 1\n",
    "    \n",
    "    star_nodes = [node for node, count in connection_count.items() if count >= 3]\n",
    "    if star_nodes:\n",
    "        print(f\"â­ STAR PATTERN NODES: {star_nodes}\")\n",
    "        print(\"   â†’ CÃ¡c node nÃ y káº¿t ná»‘i vá»›i nhiá»u node khÃ¡c, cÃ³ thá»ƒ lÃ  central processes\")\n",
    "\n",
    "def predict_and_explain_one(fusion, ds, device, sid=None, index=None,\n",
    "                            save_prefix='/kaggle/working/single_sample'):\n",
    "    assert (sid is not None) or (index is not None), \"Cáº§n truyá»n sid hoáº·c index\"\n",
    "    if sid is not None:\n",
    "        index_ = None\n",
    "        target = f\"{sid}.pt\"\n",
    "        for i, (ppath, _, _) in enumerate(ds.samples):\n",
    "            if ppath.endswith(target): index_ = i; break\n",
    "        assert index_ is not None, f\"KhÃ´ng tÃ¬m tháº¥y sid='{sid}'\"\n",
    "        index = index_\n",
    "    g, seq, label = make_single_batch(ds, index, device)\n",
    "    fusion.eval()\n",
    "    with torch.no_grad():\n",
    "        logit = fusion(g, seq)\n",
    "        prob = torch.sigmoid(logit).item()\n",
    "        pred = int(prob >= 0.5)\n",
    "    print(f\"[Inference] index={index}, label={label}, prob={prob:.4f}, pred={pred}\")\n",
    "\n",
    "    ig, fused, g_emb, s_emb = integrated_gradients_fused(fusion, g, seq, device, steps=64, baseline='zero')\n",
    "    g_dim = fusion.gcn.output_dim\n",
    "    g_score, s_score = branch_scores_from_ig(ig, g_dim)\n",
    "    g_s, s_s = float(g_score.item()), float(s_score.item())\n",
    "    dominant = 'graph' if g_s >= s_s else 'seq'\n",
    "    print(f\"[XAI-L1] graph_score={g_s:.3f} | seq_score={s_s:.3f} | dominant={dominant}\")\n",
    "\n",
    "    with open(f\"{save_prefix}_branch.csv\", 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.DictWriter(f, fieldnames=['index','label','prob','pred','graph_score','seq_score','dominant'])\n",
    "        w.writeheader()\n",
    "        w.writerow({'index': index, 'label': label, 'prob': prob, 'pred': pred,\n",
    "                    'graph_score': g_s, 'seq_score': s_s, 'dominant': dominant})\n",
    "    print(f\"[SAVE] {save_prefix}_branch.csv\")\n",
    "\n",
    "    data_i = g.to_data_list()[0]\n",
    "    data_i.batch = torch.zeros(data_i.x.size(0), dtype=torch.long, device=device)\n",
    "    \n",
    "    # Use simplified graph explanation\n",
    "    try:\n",
    "        top_nodes, top_edges, node_imp, edge_imp = explain_graph_simple(fusion, data_i, device, topk=5)\n",
    "        print(f\"[XAI-L2 Graph] top_nodes={top_nodes} | top_edges_idx={top_edges}\")\n",
    "        \n",
    "        # ğŸ”¥ THÃŠM PHÃ‚N TÃCH CHI TIáº¾T Äá»’ THá»Š\n",
    "        graph_analysis = analyze_graph_structure(data_i, top_nodes, top_edges, \n",
    "                                               save_path=f\"{save_prefix}_graph_analysis.csv\")\n",
    "        interpret_graph_patterns(graph_analysis, top_nodes, top_edges)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[XAI-L2 Graph] Failed: {e}\")\n",
    "        top_nodes, top_edges = [], []\n",
    "\n",
    "\n",
    "    top_tokens = explain_sequence_single(fusion, seq, device, ds, topk=20, steps=64)\n",
    "    preview = ', '.join([f\"{t}:{s:.3f}\" for t, s in top_tokens[:10]])\n",
    "    print(f\"[XAI-L2 Seq] top_tokens (preview 10): {preview}\")\n",
    "    with open(f\"{save_prefix}_sequence_tokens.csv\", 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.DictWriter(f, fieldnames=['rank','token','score'])\n",
    "        w.writeheader()\n",
    "        for r, (t, s) in enumerate(top_tokens, 1):\n",
    "            w.writerow({'rank': r, 'token': t, 'score': s})\n",
    "    print(f\"[SAVE] {save_prefix}_sequence_tokens.csv\")\n",
    "\n",
    "    return {'index': index, 'label': label, 'prob': prob, 'pred': pred,\n",
    "            'branch': {'graph_score': g_s, 'seq_score': s_s, 'dominant': dominant},\n",
    "            'graph_top_nodes': top_nodes, 'graph_top_edges_idx': top_edges,\n",
    "            'seq_top_tokens': top_tokens}\n",
    "\n",
    "# ===== Load model & dataset, then run =====\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load dataset (dÃ¹ng vocab_runtime.json Ä‘Ã£ save á»Ÿ Cell 1)\n",
    "jr, pr = '/kaggle/input', '/kaggle/input/1000-final/1000'\n",
    "ds = MultiModalDataset(jr, pr, vocab_json=\"/kaggle/working/vocab_runtime.json\")\n",
    "\n",
    "# Build model\n",
    "g_feats = ds[0][0].x.size(1)\n",
    "fusion = MultiModalClassifier(GCNEncoder(g_feats).to(device),\n",
    "                              xLSTMEncoder(len(ds.vocab)).to(device)).to(device)\n",
    "\n",
    "# Load weights\n",
    "fusion.load_state_dict(torch.load(\"/kaggle/input/fusion-pt/fusion_model.pt\", map_location=device))\n",
    "fusion.eval()\n",
    "print(\"Loaded /kaggle/input/fusion-pt/fusion_model.pt\")\n",
    "\n",
    "# Inference + XAI cho 1 máº«u (Ä‘á»•i index hoáº·c dÃ¹ng sid='ten_file')\n",
    "result = predict_and_explain_one(fusion, ds, device, index=2)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7725836,
     "sourceId": 12260357,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7727182,
     "sourceId": 12262574,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7790410,
     "sourceId": 12356796,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7793099,
     "sourceId": 12360675,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8579887,
     "sourceId": 13513546,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1164.87982,
   "end_time": "2025-10-29T07:06:06.976047",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-29T06:46:42.096227",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
