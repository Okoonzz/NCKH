{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298fda14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T09:01:56.611272Z",
     "iopub.status.busy": "2025-12-24T09:01:56.610530Z",
     "iopub.status.idle": "2025-12-24T09:02:04.515607Z",
     "shell.execute_reply": "2025-12-24T09:02:04.514659Z"
    },
    "papermill": {
     "duration": 7.910824,
     "end_time": "2025-12-24T09:02:04.517492",
     "exception": false,
     "start_time": "2025-12-24T09:01:56.606668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlstm\r\n",
      "  Downloading xlstm-2.0.5-py3-none-any.whl.metadata (24 kB)\r\n",
      "Collecting torch-geometric\r\n",
      "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from xlstm) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from xlstm) (0.8.1)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from xlstm) (2.0.2)\r\n",
      "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from xlstm) (3.4.0)\r\n",
      "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from xlstm) (2.3.0)\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from xlstm) (4.57.1)\r\n",
      "Collecting reportlab (from xlstm)\r\n",
      "  Downloading reportlab-4.4.7-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting joypy (from xlstm)\r\n",
      "  Downloading joypy-0.2.6-py2.py3-none-any.whl.metadata (812 bytes)\r\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from xlstm) (6.17.1)\r\n",
      "Requirement already satisfied: dacite in /usr/local/lib/python3.12/dist-packages (from xlstm) (1.9.2)\r\n",
      "Collecting ftfy (from xlstm)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from xlstm) (1.13.0)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from xlstm) (0.36.0)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from xlstm) (14.2.0)\r\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from xlstm) (0.22.1)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from xlstm) (4.67.1)\r\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from xlstm) (0.13.2)\r\n",
      "Collecting mlstm_kernels (from xlstm)\r\n",
      "  Downloading mlstm_kernels-2.0.2-py3-none-any.whl.metadata (25 kB)\r\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.10.0)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.5)\r\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->xlstm) (0.2.14)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->xlstm) (3.20.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->xlstm) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->xlstm) (6.0.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->xlstm) (4.15.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->xlstm) (1.2.1rc0)\r\n",
      "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->xlstm) (1.8.15)\r\n",
      "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->xlstm) (7.34.0)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->xlstm) (7.4.9)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->xlstm) (0.1.7)\r\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->xlstm) (1.6.0)\r\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->xlstm) (26.2.1)\r\n",
      "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->xlstm) (6.5.1)\r\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->xlstm) (5.7.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\r\n",
      "Requirement already satisfied: scipy>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from joypy->xlstm) (1.15.3)\r\n",
      "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from joypy->xlstm) (2.2.2)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from joypy->xlstm) (3.10.0)\r\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->xlstm) (4.9.3)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.12/dist-packages (from reportlab->xlstm) (11.3.0)\r\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from reportlab->xlstm) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.6.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->xlstm) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->xlstm) (2.19.2)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (3.5)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->xlstm) (3.4.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->xlstm) (2025.11.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->xlstm) (0.6.2)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->xlstm) (0.19.2)\r\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->xlstm) (4.4.2)\r\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->xlstm) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->xlstm) (3.0.52)\r\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->xlstm) (0.2.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->xlstm) (4.9.0)\r\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->xlstm) (0.4)\r\n",
      "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->xlstm) (5.9.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->xlstm) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->xlstm) (0.1.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->joypy->xlstm) (1.3.3)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->joypy->xlstm) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->joypy->xlstm) (4.60.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->joypy->xlstm) (1.4.9)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20.0->joypy->xlstm) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20.0->joypy->xlstm) (2025.3)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->xlstm) (1.3.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->xlstm) (0.8.5)\r\n",
      "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel->xlstm) (4.5.1)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->xlstm) (0.7.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->xlstm) (1.17.0)\r\n",
      "Downloading xlstm-2.0.5-py3-none-any.whl (91 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.7/91.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading joypy-0.2.6-py2.py3-none-any.whl (8.6 kB)\r\n",
      "Downloading mlstm_kernels-2.0.2-py3-none-any.whl (349 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading reportlab-4.4.7-py3-none-any.whl (2.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: reportlab, ftfy, torch-geometric, joypy, mlstm_kernels, xlstm\r\n",
      "Successfully installed ftfy-6.3.1 joypy-0.2.6 mlstm_kernels-2.0.2 reportlab-4.4.7 torch-geometric-2.7.0 xlstm-2.0.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install xlstm torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcd3cfbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T09:02:04.526123Z",
     "iopub.status.busy": "2025-12-24T09:02:04.525842Z",
     "iopub.status.idle": "2025-12-24T12:21:08.723870Z",
     "shell.execute_reply": "2025-12-24T12:21:08.723057Z"
    },
    "papermill": {
     "duration": 11944.207805,
     "end_time": "2025-12-24T12:21:08.728493",
     "exception": false,
     "start_time": "2025-12-24T09:02:04.520688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Vocab size = 4509056\n",
      "[INFO] Using device: cuda\n",
      "\n",
      "=== [SEQ_LEN=1500] (RETRAIN, train CLEAN, test NOISE) ===\n",
      "[INFO] Tổng số sample: 4215\n",
      "[INFO][CLEAN] Found 4215 samples (before splitting)\n",
      "[INFO] Build split for CLEAN dataset (train/val, domain=2021 vs early-2025)\n",
      "[INFO] Split indices from metadata: train=3020, val=521, test=651, missing_meta=23\n",
      "[INFO] Node feature dim = 768\n",
      "[Epoch 1] Train Loss=0.226061, Train Acc=0.901325 | Val Loss=0.168185, Val Acc=0.980806, Val F1=0.984375\n",
      "[Epoch 2] Train Loss=0.117203, Train Acc=0.943709 | Val Loss=0.226202, Val Acc=0.982726, Val F1=0.985959\n",
      "[Epoch 3] Train Loss=0.101480, Train Acc=0.949338 | Val Loss=0.285060, Val Acc=0.980806, Val F1=0.984375\n",
      "[Epoch 4] Train Loss=0.096630, Train Acc=0.951987 | Val Loss=0.274868, Val Acc=0.976967, Val F1=0.981191\n",
      "[Epoch 5] Train Loss=0.090049, Train Acc=0.962252 | Val Loss=0.188720, Val Acc=0.986564, Val F1=0.989114\n",
      "[Epoch 6] Train Loss=0.048711, Train Acc=0.983775 | Val Loss=0.260123, Val Acc=0.978887, Val F1=0.982786\n",
      "[Epoch 7] Train Loss=0.043949, Train Acc=0.986424 | Val Loss=0.301210, Val Acc=0.976967, Val F1=0.981191\n",
      "[Epoch 8] Train Loss=0.035501, Train Acc=0.987417 | Val Loss=0.066801, Val Acc=0.980806, Val F1=0.984277\n",
      "[Epoch 9] Train Loss=0.033992, Train Acc=0.987086 | Val Loss=0.079777, Val Acc=0.976967, Val F1=0.981191\n",
      "[Epoch 10] Train Loss=0.035623, Train Acc=0.988079 | Val Loss=0.111773, Val Acc=0.978887, Val F1=0.982786\n",
      "Early stopping.\n",
      "[INFO] Tổng số sample: 4215\n",
      "[INFO][NOISE] Found 4215 samples (before splitting)\n",
      "[INFO] Build split for NOISE dataset (chỉ dùng test_idx_noise)\n",
      "[INFO] Split indices from metadata: train=3020, val=521, test=651, missing_meta=23\n",
      ">>> TEST NOISE (2025 noise, RETRAIN) => Loss=0.594376, Acc=0.897081, TPR=0.910112, FPR=0.131068, Precision=0.937500, Recall=0.910112, F1=0.923603\n",
      "\n",
      "=========== DRIFT REPORT (PSI) [RANSOMWARE YEAR] ===========\n",
      "[SET] ref_ran=1633 (train+val,2021) | cur_ran=445 (test,2025)\n",
      "[PSI] PSI(prob)   ransom-only: 2.909510\n",
      "[PSI] PSI(w_graph) ransom-only: 0.740527\n",
      "[PSI] PSI(w_seq)   ransom-only: 0.740527\n",
      "===========================================================\n",
      "\n",
      "[DRIFT_STATS] {'psi_prob_ransom': 2.9095095611191013, 'psi_w_graph_ransom': 0.740527433553641, 'psi_w_seq_ransom': 0.7405274335536411, 'refN_ransom': 1633, 'curN_ransom': 445}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, BatchNorm\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# xLSTM\n",
    "from xlstm import (\n",
    "    xLSTMBlockStack, xLSTMBlockStackConfig,\n",
    "    mLSTMBlockConfig, mLSTMLayerConfig,\n",
    "    sLSTMBlockConfig, sLSTMLayerConfig,\n",
    "    FeedForwardConfig\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# Dataset\n",
    "# ======================================================\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Để kết quả ổn định hơn trên GPU (có thể chậm hơn chút)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def normalize_name(name):\n",
    "    \"\"\"\n",
    "    Chuẩn hoá tên file:\n",
    "    - Bỏ đuôi _seq.pt hoặc .pt\n",
    "    - Bỏ phần .exe, .EXE, .ex, .EX...\n",
    "    \"\"\"\n",
    "    name = name.replace(\"_seq.pt\", \"\")\n",
    "    name = name.replace(\".pt\", \"\")\n",
    "    name = re.sub(r\"\\.(e?xe?)$\", \"\", name, flags=re.IGNORECASE)\n",
    "    return name\n",
    "\n",
    "\n",
    "class MultiModalDatasetPT(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset đọc graph .pt + seq_ids .pt\n",
    "    - Hỗ trợ:\n",
    "        + 1 thư mục benign graph + benign seq (benign_seq_root)\n",
    "        + nhiều thư mục ransomware graph + ransomware seq (ransomware_seq_root)\n",
    "    - Cho phép:\n",
    "        + CLEAN: benign_seq_root = ransomware_seq_root = seq_ids clean\n",
    "        + NOISE: benign_seq_root = seq_ids clean, ransomware_seq_root = seq_ids_noise\n",
    "    - Tự xử lý graph rỗng bằng cách tạo dummy node\n",
    "    - Gắn thêm cờ has_graph cho mỗi sample\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        benign_graph_dir,\n",
    "        ransomware_graph_dirs,\n",
    "        benign_seq_root,\n",
    "        ransomware_seq_root,\n",
    "        max_seq_len=1500\n",
    "    ):\n",
    "        self.max_len = max_seq_len\n",
    "        self.samples = []\n",
    "\n",
    "        mapping = []\n",
    "\n",
    "        # Benign\n",
    "        mapping.append((benign_graph_dir, os.path.join(benign_seq_root, \"benign\"), 0))\n",
    "\n",
    "        # Ransomware\n",
    "        for r_dir in ransomware_graph_dirs:\n",
    "            mapping.append((r_dir, os.path.join(ransomware_seq_root, \"ransomware\"), 1))\n",
    "\n",
    "        # Gom tất cả cặp (graph, seq, label)\n",
    "        for gdir, sdir, label in mapping:\n",
    "            if not (os.path.isdir(gdir) and os.path.isdir(sdir)):\n",
    "                print(f\"[WARN] Thiếu thư mục: {gdir} hoặc {sdir}\")\n",
    "                continue\n",
    "\n",
    "            graph_map = {}\n",
    "            for f in sorted(os.listdir(gdir)):\n",
    "                if f.endswith(\".pt\"):\n",
    "                    norm = normalize_name(f)\n",
    "                    graph_map[norm] = os.path.join(gdir, f)\n",
    "\n",
    "            for fname in sorted(os.listdir(sdir)):\n",
    "                if not fname.endswith(\"_seq.pt\"):\n",
    "                    continue\n",
    "                norm = normalize_name(fname)\n",
    "                spath = os.path.join(sdir, fname)\n",
    "\n",
    "                if norm in graph_map:\n",
    "                    ppath = graph_map[norm]\n",
    "                    self.samples.append((ppath, spath, label))\n",
    "\n",
    "        if not self.samples:\n",
    "            raise RuntimeError(\"Không tìm thấy cặp graph + seq nào. Kiểm tra tên file & thư mục.\")\n",
    "\n",
    "        self.samples.sort(key=lambda x: x[0])\n",
    "\n",
    "        print(f\"[INFO] Tổng số sample: {len(self.samples)}\")\n",
    "\n",
    "        # Suy ra feat_dim từ một graph hợp lệ\n",
    "        self.feat_dim = None\n",
    "        for g_path, s_path, lbl in self.samples:\n",
    "            data = torch.load(g_path, weights_only=False)\n",
    "            if hasattr(data, \"x\") and data.x is not None and data.x.dim() == 2 and data.x.size(0) > 0:\n",
    "                self.feat_dim = data.x.size(1)\n",
    "                break\n",
    "\n",
    "        if self.feat_dim is None:\n",
    "            raise RuntimeError(\"Không tìm được graph hợp lệ để suy ra feat_dim!\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ppath, spath, label = self.samples[i]\n",
    "\n",
    "        data = torch.load(ppath, weights_only=False)\n",
    "        seq_ids = torch.load(spath)\n",
    "\n",
    "        # Xử lý graph rỗng: tạo dummy node + cờ has_graph\n",
    "        has_real_graph = True\n",
    "        if (not hasattr(data, \"x\")) or (data.x is None) or (data.x.dim() != 2) or (data.x.size(0) == 0):\n",
    "            has_real_graph = False\n",
    "            data.x = torch.zeros((1, self.feat_dim), dtype=torch.float32)\n",
    "            data.edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "        data.has_graph = torch.tensor(1 if has_real_graph else 0, dtype=torch.long)\n",
    "\n",
    "        # Pad/cắt sequence\n",
    "        if self.max_len is not None:\n",
    "            if seq_ids.size(0) > self.max_len:\n",
    "                seq_ids = seq_ids[:self.max_len]\n",
    "            else:\n",
    "                pad_len = self.max_len - seq_ids.size(0)\n",
    "                pad = torch.zeros(pad_len, dtype=seq_ids.dtype)\n",
    "                seq_ids = torch.cat([seq_ids, pad], dim=0)\n",
    "\n",
    "        return data, seq_ids, torch.tensor(int(label), dtype=torch.float32)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    graphs, seqs, labels = zip(*batch)\n",
    "    return Batch.from_data_list(graphs), torch.stack(seqs), torch.stack(labels)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Encoders & Fusion classifier với gating w_seq / w_graph\n",
    "# ======================================================\n",
    "\n",
    "class GCNEncoder(nn.Module):\n",
    "    def __init__(self, in_feats, hidden=64, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_feats, hidden)\n",
    "        self.bn1 = BatchNorm(hidden)\n",
    "        self.conv2 = GCNConv(hidden, hidden)\n",
    "        self.bn2 = BatchNorm(hidden)\n",
    "        self.drop = drop\n",
    "        self.output_dim = hidden\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = F.dropout(x, self.drop, training=self.training)\n",
    "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
    "        x = F.dropout(x, self.drop, training=self.training)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "\n",
    "class xLSTMEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed=128, seq_len=1500, blocks=1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed, padding_idx=0)\n",
    "\n",
    "        cfg = xLSTMBlockStackConfig(\n",
    "            mlstm_block=mLSTMBlockConfig(\n",
    "                mlstm=mLSTMLayerConfig(\n",
    "                    conv1d_kernel_size=4,\n",
    "                    qkv_proj_blocksize=4,\n",
    "                    num_heads=4\n",
    "                )\n",
    "            ),\n",
    "            slstm_block=sLSTMBlockConfig(\n",
    "                slstm=sLSTMLayerConfig(\n",
    "                    backend=\"vanilla\",\n",
    "                    num_heads=4,\n",
    "                    conv1d_kernel_size=4,\n",
    "                    bias_init=\"powerlaw_blockdependent\"\n",
    "                ),\n",
    "                feedforward=FeedForwardConfig(\n",
    "                    proj_factor=1.3,\n",
    "                    act_fn=\"gelu\"\n",
    "                )\n",
    "            ),\n",
    "            context_length=seq_len,\n",
    "            num_blocks=blocks,\n",
    "            embedding_dim=embed,\n",
    "            slstm_at=[0]\n",
    "        )\n",
    "\n",
    "        self.xlstm = xLSTMBlockStack(cfg)\n",
    "        self.output_dim = embed\n",
    "\n",
    "    def forward(self, seq):\n",
    "        out = self.xlstm(self.embed(seq))  # [B, L, D]\n",
    "        return out.mean(dim=1)             # [B, D]\n",
    "\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, in_dim, hiddens=[128, 64], drop=0.3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        dims = [in_dim] + hiddens\n",
    "        for i in range(len(hiddens)):\n",
    "            layers.extend([\n",
    "                nn.Linear(dims[i], dims[i + 1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(drop)\n",
    "            ])\n",
    "        layers.append(nn.Linear(dims[-1], 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.mlp(x)   # [B, 1]\n",
    "        return out.view(-1) # [B]\n",
    "\n",
    "\n",
    "class MultiModalClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    F: encoder chung cho cả source/target\n",
    "       - GCNEncoder + xLSTMEncoder\n",
    "       - Gating w_seq / w_graph\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_enc, seq_enc, fusion_h=128):\n",
    "        super().__init__()\n",
    "        self.graph_enc = graph_enc\n",
    "        self.seq_enc = seq_enc\n",
    "\n",
    "        d_g = graph_enc.output_dim\n",
    "        d_s = seq_enc.output_dim\n",
    "\n",
    "        # Gate: cho ra 2 logit (seq, graph)\n",
    "        self.gate = nn.Linear(d_s + d_g, 2)\n",
    "\n",
    "        fusion_dim = d_g + d_s\n",
    "        self.fusion_dim = fusion_dim   # dùng cho DomainDiscriminator\n",
    "        self.classifier = MLPClassifier(fusion_dim, [fusion_h, fusion_h // 2])\n",
    "\n",
    "    def forward(self, g, seq, return_branch=False, return_features=False):\n",
    "        h_g = self.graph_enc(g.x, g.edge_index, g.batch)\n",
    "        h_s = self.seq_enc(seq)\n",
    "\n",
    "        # Nếu batch graph và batch seq lệch thì cắt theo min\n",
    "        if h_g.size(0) != h_s.size(0):\n",
    "            b = min(h_g.size(0), h_s.size(0))\n",
    "            h_g = h_g[:b]\n",
    "            h_s = h_s[:b]\n",
    "            if hasattr(g, \"has_graph\"):\n",
    "                g.has_graph = g.has_graph[:b]\n",
    "\n",
    "        B = h_s.size(0)\n",
    "        if hasattr(g, \"has_graph\"):\n",
    "            has_graph = g.has_graph.view(-1).to(h_g.device).float()\n",
    "        else:\n",
    "            has_graph = torch.ones(B, device=h_g.device)\n",
    "\n",
    "        # ép h_g = 0 nếu không có graph\n",
    "        h_g = h_g * has_graph.view(-1, 1)\n",
    "\n",
    "        # logit branch\n",
    "        gate_in = torch.cat([h_s, h_g], dim=-1)      # [B, d_s + d_g]\n",
    "        scores = self.gate(gate_in)                  # [B, 2]\n",
    "\n",
    "        # ép logit graph nhỏ nếu has_graph=0\n",
    "        scores[:, 1] = scores[:, 1] + (has_graph - 1.0) * 1e4\n",
    "\n",
    "        w = torch.softmax(scores, dim=-1)            # [B, 2]\n",
    "        w_seq = w[:, 0:1]\n",
    "        w_graph = w[:, 1:2]\n",
    "\n",
    "        h_fused = torch.cat([w_seq * h_s, w_graph * h_g], dim=-1)\n",
    "        logits = self.classifier(h_fused)\n",
    "\n",
    "        if not return_branch and not return_features:\n",
    "            return logits\n",
    "\n",
    "        branch_info = {\n",
    "            \"w_seq\": w_seq.detach().cpu(),\n",
    "            \"w_graph\": w_graph.detach().cpu(),\n",
    "            \"has_graph\": has_graph.detach().cpu()\n",
    "        }\n",
    "\n",
    "        if return_branch and not return_features:\n",
    "            return logits, branch_info\n",
    "        if return_features and not return_branch:\n",
    "            return logits, h_fused\n",
    "        if return_branch and return_features:\n",
    "            return logits, h_fused, branch_info\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Adversarial DA: GRL + Domain Discriminator\n",
    "# ======================================================\n",
    "\n",
    "class GradReverse(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambd):\n",
    "        ctx.lambd = lambd\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -ctx.lambd * grad_output, None\n",
    "\n",
    "\n",
    "def grad_reverse(x, lambd=1.0):\n",
    "    return GradReverse.apply(x, lambd)\n",
    "\n",
    "\n",
    "class DomainDiscriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    D: phân biệt feature thuộc domain source (0) hay target (1).\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, hidden=128, drop=0.3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(hidden, hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(hidden // 2, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, feat, lambd=1.0):\n",
    "        feat_rev = grad_reverse(feat, lambd)\n",
    "        out = self.net(feat_rev)\n",
    "        return out.squeeze(1)\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Dataset wrapper để thêm domain label\n",
    "# ======================================================\n",
    "\n",
    "class DomainSubset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrapper: (ds, indices, domain_labels) -> (graph, seq, label, domain_id)\n",
    "    domain_id: 0 = source, 1 = target\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ds, indices, domain_labels):\n",
    "        self.base_ds = base_ds\n",
    "        self.indices = sorted(indices)\n",
    "        self.domain_labels = domain_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        g, seq, y = self.base_ds[real_idx]\n",
    "        d = self.domain_labels[real_idx]\n",
    "        return g, seq, y, torch.tensor(float(d), dtype=torch.float32)\n",
    "\n",
    "\n",
    "def collate_fn_da(batch):\n",
    "    graphs, seqs, labels, domains = zip(*batch)\n",
    "    return (\n",
    "        Batch.from_data_list(graphs),\n",
    "        torch.stack(seqs),\n",
    "        torch.stack(labels),\n",
    "        torch.stack(domains),\n",
    "    )\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Train / Eval\n",
    "# ======================================================\n",
    "\n",
    "def train_epoch_da(\n",
    "    model,\n",
    "    domain_disc,\n",
    "    loader,\n",
    "    cls_crit,\n",
    "    dom_crit,\n",
    "    opt_main,\n",
    "    opt_disc,\n",
    "    device,\n",
    "    lambda_da=1.0,\n",
    "    alpha_dom=0.1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train 1 epoch với Adversarial DA:\n",
    "      L_total = L_cls + alpha_dom * L_domain\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    domain_disc.train()\n",
    "    total_loss = total_cls = total_dom = 0.0\n",
    "    correct, total = 0, 0\n",
    "    dom_correct, dom_total = 0, 0\n",
    "\n",
    "    for g, seq, labs, doms in loader:\n",
    "        g, seq, labs, doms = g.to(device), seq.to(device), labs.to(device), doms.to(device)\n",
    "\n",
    "        opt_main.zero_grad()\n",
    "        opt_disc.zero_grad()\n",
    "\n",
    "        # 1) Forward encoder + classifier => logits, feat\n",
    "        logits, feat = model(g, seq, return_features=True)\n",
    "\n",
    "        # Align batch nếu mismatch\n",
    "        b_log, b_lab = logits.size(0), labs.size(0)\n",
    "        if b_log != b_lab:\n",
    "            b = min(b_log, b_lab)\n",
    "            logits = logits[:b]\n",
    "            labs = labs[:b]\n",
    "            doms = doms[:b]\n",
    "            feat = feat[:b]\n",
    "\n",
    "        # 2) Classification loss\n",
    "        cls_loss = cls_crit(logits, labs)\n",
    "\n",
    "        # 3) Domain loss (adversarial nhờ GRL)\n",
    "        dom_logits = domain_disc(feat, lambd=lambda_da)\n",
    "        dom_loss = dom_crit(dom_logits, doms)\n",
    "\n",
    "        # 4) Tổng loss\n",
    "        loss = cls_loss + alpha_dom * dom_loss\n",
    "\n",
    "        loss.backward()\n",
    "        opt_main.step()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # ====== Thống kê ======\n",
    "        total_loss += loss.item() * labs.size(0)\n",
    "        total_cls += cls_loss.item() * labs.size(0)\n",
    "        total_dom += dom_loss.item() * labs.size(0)\n",
    "\n",
    "        # acc phân loại ransomware/benign\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct += (preds == labs).sum().item()\n",
    "        total += labs.size(0)\n",
    "\n",
    "        # acc domain (source/target) của D\n",
    "        dom_pred = (torch.sigmoid(dom_logits) > 0.5).float()\n",
    "        dom_correct += (dom_pred == doms).sum().item()\n",
    "        dom_total += doms.size(0)\n",
    "\n",
    "    return {\n",
    "        \"loss\": total_loss / total,\n",
    "        \"cls_loss\": total_cls / total,\n",
    "        \"dom_loss\": total_dom / total,\n",
    "        \"acc\": correct / total,\n",
    "        \"dom_acc\": dom_correct / max(dom_total, 1e-9),\n",
    "    }\n",
    "\n",
    "\n",
    "def train_epoch(model, loader, crit, opt, device):\n",
    "    \"\"\"\n",
    "    Train thường (không DA) – giữ lại nếu muốn chạy baseline.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for g, seq, labs in loader:\n",
    "        g, seq, labs = g.to(device), seq.to(device), labs.to(device)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        logits = model(g, seq)\n",
    "\n",
    "        if logits.size(0) != labs.size(0):\n",
    "            b = min(logits.size(0), labs.size(0))\n",
    "            logits = logits[:b]\n",
    "            labs = labs[:b]\n",
    "\n",
    "        loss = crit(logits, labs)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item() * labs.size(0)\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct += (preds == labs).sum().item()\n",
    "        total += labs.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def eval_metrics(model, loader, crit, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for g, seq, labs in loader:\n",
    "            g, seq, labs = g.to(device), seq.to(device), labs.to(device)\n",
    "            logits = model(g, seq)\n",
    "\n",
    "            if logits.size(0) != labs.size(0):\n",
    "                b = min(logits.size(0), labs.size(0))\n",
    "                logits = logits[:b]\n",
    "                labs = labs[:b]\n",
    "\n",
    "            total_loss += crit(logits, labs).item() * labs.size(0)\n",
    "\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            all_preds.extend(preds.cpu().tolist())\n",
    "            all_labels.extend(labs.cpu().tolist())\n",
    "\n",
    "    if len(set(all_labels)) < 2:\n",
    "        return {\n",
    "            'loss': total_loss,\n",
    "            'acc': 0, 'tpr': 0, 'fpr': 0,\n",
    "            'precision': 0, 'recall': 0, 'f1': 0\n",
    "        }\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "    total = tp + tn + fp + fn\n",
    "\n",
    "    return {\n",
    "        'loss': total_loss / total,\n",
    "        'acc': (tp + tn) / total,\n",
    "        'tpr': tp / (tp + fn + 1e-9),\n",
    "        'fpr': fp / (fp + tn + 1e-9),\n",
    "        'precision': precision_score(all_labels, all_preds),\n",
    "        'recall': recall_score(all_labels, all_preds),\n",
    "        'f1': f1_score(all_labels, all_preds)\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# PSI utilities – drift CLEAN vs NOISE (ransomware-only)\n",
    "# ======================================================\n",
    "\n",
    "def _is_ransom(ds, idx: int) -> bool:\n",
    "    \"\"\"\n",
    "    Kiểm tra sample ở ds.samples[idx] có phải ransomware (label=1) hay không.\n",
    "    \"\"\"\n",
    "    return int(ds.samples[idx][2]) == 1\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_model_outputs_branch(model, ds, indices, device, batch_size=32):\n",
    "    \"\"\"\n",
    "    Thu output cho PSI từ 1 dataset:\n",
    "      - prob = sigmoid(logits)\n",
    "      - w_seq, w_graph (từ gating)\n",
    "    \"\"\"\n",
    "    if len(indices) == 0:\n",
    "        return {\"prob\": np.array([]), \"w_seq\": np.array([]), \"w_graph\": np.array([])}\n",
    "\n",
    "    loader = DataLoader(\n",
    "        Subset(ds, indices),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    probs, wseqs, wgraphs = [], [], []\n",
    "\n",
    "    for g, seq, _ in loader:\n",
    "        g = g.to(device)\n",
    "        seq = seq.to(device)\n",
    "\n",
    "        logits, br = model(g, seq, return_branch=True)\n",
    "        p = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "\n",
    "        probs.append(p)\n",
    "        wseqs.append(br[\"w_seq\"].numpy().reshape(-1))\n",
    "        wgraphs.append(br[\"w_graph\"].numpy().reshape(-1))\n",
    "\n",
    "    return {\n",
    "        \"prob\": np.concatenate(probs, axis=0),\n",
    "        \"w_seq\": np.concatenate(wseqs, axis=0),\n",
    "        \"w_graph\": np.concatenate(wgraphs, axis=0),\n",
    "    }\n",
    "\n",
    "\n",
    "def make_bins_from_reference(ref_values, n_bins=10, strategy=\"quantile\"):\n",
    "    ref_values = np.asarray(ref_values)\n",
    "    if ref_values.size == 0:\n",
    "        edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "        edges[0] = -np.inf\n",
    "        edges[-1] = np.inf\n",
    "        return edges\n",
    "\n",
    "    if strategy == \"fixed\":\n",
    "        edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    else:\n",
    "        qs = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "        edges = np.quantile(ref_values, qs)\n",
    "        edges = np.unique(edges)\n",
    "        if len(edges) < 3:\n",
    "            edges = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "\n",
    "    edges[0] = -np.inf\n",
    "    edges[-1] = np.inf\n",
    "    return edges\n",
    "\n",
    "\n",
    "def psi(expected, actual, bin_edges, eps=1e-6):\n",
    "    expected = np.asarray(expected)\n",
    "    actual = np.asarray(actual)\n",
    "\n",
    "    e_counts, _ = np.histogram(expected, bins=bin_edges)\n",
    "    a_counts, _ = np.histogram(actual, bins=bin_edges)\n",
    "\n",
    "    e_perc = e_counts / max(e_counts.sum(), 1)\n",
    "    a_perc = a_counts / max(a_counts.sum(), 1)\n",
    "\n",
    "    e_perc = np.clip(e_perc, eps, None)\n",
    "    a_perc = np.clip(a_perc, eps, None)\n",
    "\n",
    "    return float(np.sum((a_perc - e_perc) * np.log(a_perc / e_perc)))\n",
    "\n",
    "\n",
    "def report_year_drift_psi_ransom_only(\n",
    "    model, ds,\n",
    "    tr_idx, val_idx, test_idx,\n",
    "    domain_labels,\n",
    "    device,\n",
    "    batch_size=32,\n",
    "    n_bins=10,\n",
    "    bin_strategy_prob=\"quantile\",\n",
    "    bin_strategy_w=\"fixed\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Concept drift (YEAR) cho ransomware:\n",
    "      Ref = (train+val) ∩ domain=0(2021) ∩ y=1\n",
    "      Cur = test        ∩ domain=1(2025) ∩ y=1\n",
    "    \"\"\"\n",
    "    ref_idx = [i for i in (tr_idx + val_idx) if domain_labels[i] == 0 and _is_ransom(ds, i)]\n",
    "    cur_idx = [i for i in test_idx if domain_labels[i] == 1 and _is_ransom(ds, i)]\n",
    "\n",
    "    print(\"\\n=========== DRIFT REPORT (PSI) [RANSOMWARE YEAR] ===========\")\n",
    "    print(f\"[SET] ref_ran={len(ref_idx)} (train+val,2021) | cur_ran={len(cur_idx)} (test,2025)\")\n",
    "\n",
    "    if len(ref_idx) == 0 or len(cur_idx) == 0:\n",
    "        print(\"[ERROR] Thiếu ransomware ở ref hoặc cur => không tính PSI được.\")\n",
    "        print(\"===========================================================\\n\")\n",
    "        return None\n",
    "\n",
    "    ref_out = collect_model_outputs_branch(model, ds, ref_idx, device, batch_size=batch_size)\n",
    "    cur_out = collect_model_outputs_branch(model, ds, cur_idx, device, batch_size=batch_size)\n",
    "\n",
    "    edges_prob = make_bins_from_reference(ref_out[\"prob\"], n_bins=n_bins, strategy=bin_strategy_prob)\n",
    "    psi_prob = psi(ref_out[\"prob\"], cur_out[\"prob\"], edges_prob)\n",
    "\n",
    "    edges_w = make_bins_from_reference(ref_out[\"w_graph\"], n_bins=n_bins, strategy=bin_strategy_w)\n",
    "    psi_wg = psi(ref_out[\"w_graph\"], cur_out[\"w_graph\"], edges_w)\n",
    "    psi_ws = psi(ref_out[\"w_seq\"],   cur_out[\"w_seq\"],   edges_w)\n",
    "\n",
    "    print(f\"[PSI] PSI(prob)   ransom-only: {psi_prob:.6f}\")\n",
    "    print(f\"[PSI] PSI(w_graph) ransom-only: {psi_wg:.6f}\")\n",
    "    print(f\"[PSI] PSI(w_seq)   ransom-only: {psi_ws:.6f}\")\n",
    "    print(\"===========================================================\\n\")\n",
    "\n",
    "    return {\n",
    "        \"psi_prob_ransom\": psi_prob,\n",
    "        \"psi_w_graph_ransom\": psi_wg,\n",
    "        \"psi_w_seq_ransom\": psi_ws,\n",
    "        \"refN_ransom\": len(ref_idx),\n",
    "        \"curN_ransom\": len(cur_idx),\n",
    "    }\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Split từ metadata + domain label (source/target)\n",
    "# ======================================================\n",
    "\n",
    "def build_split_indices_from_metadata(ds, metadata_csv_path):\n",
    "    \"\"\"\n",
    "    metadata.csv:\n",
    "      - filename: 'report_xxx.json'\n",
    "      - split_KB1: 'train' / 'val' / 'test'\n",
    "      - domain: 'source' / 'target' (hoặc pre/old/2021 vs post/new/2025...)\n",
    "\n",
    "    Trả về:\n",
    "      - train_idx, val_idx, test_idx\n",
    "      - domain_labels: list cùng độ dài ds.samples, mỗi phần tử là 0 (source) hoặc 1 (target)\n",
    "    \"\"\"\n",
    "    split_map = {}   # base_name -> (split, dom_id)\n",
    "\n",
    "    with open(metadata_csv_path, newline='', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            fname = row['filename']            # ví dụ 'report_abc123.json'\n",
    "            base = os.path.splitext(fname)[0]  # 'report_abc123'\n",
    "            split = row['split_KB1'].strip().lower()\n",
    "\n",
    "            dom_str = row.get('domain', 'source').strip().lower()\n",
    "            if dom_str in ('source', 'src', 's', 'pre', 'old', '2021'):\n",
    "                dom_id = 0\n",
    "            elif dom_str in ('target', 'tgt', 't', 'post', 'new', '2025'):\n",
    "                dom_id = 1\n",
    "            else:\n",
    "                dom_id = 0  # default source\n",
    "\n",
    "            split_map[base] = (split, dom_id)\n",
    "\n",
    "    train_idx, val_idx, test_idx = [], [], []\n",
    "    domain_labels = [0] * len(ds.samples)\n",
    "    missing = 0\n",
    "\n",
    "    for idx, (g_path, seq_path, lbl) in enumerate(ds.samples):\n",
    "        base_g = os.path.splitext(os.path.basename(g_path))[0]\n",
    "        val = split_map.get(base_g)\n",
    "\n",
    "        if val is None:\n",
    "            missing += 1\n",
    "            continue\n",
    "\n",
    "        split, dom_id = val\n",
    "        domain_labels[idx] = dom_id\n",
    "\n",
    "        if split == \"train\":\n",
    "            train_idx.append(idx)\n",
    "        elif split == \"val\":\n",
    "            val_idx.append(idx)\n",
    "        elif split == \"test\":\n",
    "            test_idx.append(idx)\n",
    "        else:\n",
    "            missing += 1\n",
    "\n",
    "    train_idx = sorted(train_idx)\n",
    "    val_idx = sorted(val_idx)\n",
    "    test_idx = sorted(test_idx)\n",
    "\n",
    "    print(f\"[INFO] Split indices from metadata: \"\n",
    "          f\"train={len(train_idx)}, val={len(val_idx)}, test={len(test_idx)}, \"\n",
    "          f\"missing_meta={missing}\")\n",
    "    return train_idx, val_idx, test_idx, domain_labels\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Run function (GCN + xLSTM + Adversarial DA)\n",
    "# ======================================================\n",
    "\n",
    "def run_gcn_xlstm():\n",
    "    # ===== GRAPH PATHS =====\n",
    "    benign_graph_dir = \"/kaggle/input/2026benign-1633rans21/PYGdata_benign_2026_Rans21_1633/benign\"\n",
    "\n",
    "    # ransomware CLEAN (2021 + 2025)\n",
    "    rans21_clean_graph_dir = \"/kaggle/input/2026benign-1633rans21/PYGdata_benign_2026_Rans21_1633/ransomware\"\n",
    "    rans25_clean_graph_dir = \"/kaggle/input/557rans25/pyg_data_DistilBERT_ransomware2025/ransomware\"\n",
    "\n",
    "    # ransomware NOISE (2021 + 2025)\n",
    "    rans21_noise_graph_dir = \"/kaggle/input/data-rans21-noise/pyg_data_DistilBERT_ransomware2021_noise/ransomware\"\n",
    "    rans25_noise_graph_dir = \"/kaggle/input/data-rans25-noise/pyg_data_DistilBERT_ransomware2025_noise/ransomware\"\n",
    "\n",
    "    ransomware_graph_dirs_clean = [\n",
    "        rans21_clean_graph_dir,\n",
    "        rans25_clean_graph_dir,\n",
    "    ]\n",
    "    ransomware_graph_dirs_noise = [\n",
    "        rans21_noise_graph_dir,\n",
    "        rans25_noise_graph_dir,\n",
    "    ]\n",
    "\n",
    "    # ===== SEQ PATHS =====\n",
    "    benign_seq_root = \"/kaggle/input/seq-ids/seq_ids\"\n",
    "    ransomware_seq_root_clean = \"/kaggle/input/seq-ids/seq_ids\"\n",
    "    ransomware_seq_root_noise = \"/kaggle/input/seq-ids-noise/seq_ids_noise\"\n",
    "\n",
    "    # ===== Vocab & metadata =====\n",
    "    vocab_json_path = \"/kaggle/input/seq-vocab/vocab_runtime.json\"\n",
    "    metadata_csv_path = \"/kaggle/input/csv-kb1-q/metadata_KB1_Q.csv\"\n",
    "\n",
    "    # Load vocab\n",
    "    with open(vocab_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        vocab = json.load(f)\n",
    "    vocab_size = len(vocab)\n",
    "    print(f\"[INFO] Vocab size = {vocab_size}\")\n",
    "\n",
    "    seq_len_options = [1500]\n",
    "    batch_size = 8\n",
    "    lr = 1e-3\n",
    "    epochs = 20\n",
    "    patience = 5\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"[INFO] Using device: {device}\")\n",
    "\n",
    "    for seq_len in seq_len_options:\n",
    "        print(f\"\\n=== [SEQ_LEN={seq_len}] (RETRAIN, train CLEAN, test NOISE) ===\")\n",
    "\n",
    "        # ===== Dataset CLEAN cho train/val (2021 + early 2025, không noise) =====\n",
    "        try:\n",
    "            ds_clean = MultiModalDatasetPT(\n",
    "                benign_graph_dir,\n",
    "                ransomware_graph_dirs_clean,\n",
    "                benign_seq_root=benign_seq_root,\n",
    "                ransomware_seq_root=ransomware_seq_root_clean,\n",
    "                max_seq_len=seq_len\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            print(f\"[WARN] {e} → skip combo này.\")\n",
    "            return\n",
    "\n",
    "        print(f\"[INFO][CLEAN] Found {len(ds_clean)} samples (before splitting)\")\n",
    "\n",
    "        if len(ds_clean) < 10:\n",
    "            print(\"[WARNING] Not enough CLEAN samples. Skipping...\")\n",
    "            return\n",
    "\n",
    "        # Split + domain label từ metadata cho CLEAN\n",
    "        print(\"[INFO] Build split for CLEAN dataset (train/val, domain=2021 vs early-2025)\")\n",
    "        tr_idx, val_idx, test_idx_clean, domain_labels_clean = build_split_indices_from_metadata(\n",
    "            ds_clean, metadata_csv_path\n",
    "        )\n",
    "        if min(len(tr_idx), len(val_idx)) == 0:\n",
    "            print(\"[ERROR] train hoặc val rỗng. Kiểm tra metadata_KB1_final.csv.\")\n",
    "            return\n",
    "\n",
    "        # Dataloader cho RETRAIN (không dùng domain label trong training)\n",
    "        tr_loader = DataLoader(\n",
    "            Subset(ds_clean, tr_idx),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            Subset(ds_clean, val_idx),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        # Lấy feature dim từ sample CLEAN\n",
    "        sample_g, _, _ = ds_clean[0]\n",
    "        in_feats = sample_g.x.size(1)\n",
    "        print(f\"[INFO] Node feature dim = {in_feats}\")\n",
    "\n",
    "        # Encoders + classifier\n",
    "        graph_enc = GCNEncoder(in_feats).to(device)\n",
    "        seq_enc = xLSTMEncoder(vocab_size, seq_len=seq_len).to(device)\n",
    "        model = MultiModalClassifier(graph_enc, seq_enc).to(device)\n",
    "\n",
    "        cls_crit = nn.BCEWithLogitsLoss()\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        best_f1 = 0.0\n",
    "        no_improve = 0\n",
    "        best_state = None\n",
    "\n",
    "        # ===== Train RETRAIN (không DA) trên CLEAN (2021 + early 2025) =====\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            tr_loss, tr_acc = train_epoch(\n",
    "                model,\n",
    "                tr_loader,\n",
    "                crit=cls_crit,\n",
    "                opt=opt,\n",
    "                device=device\n",
    "            )\n",
    "            val_met = eval_metrics(model, val_loader, cls_crit, device)\n",
    "\n",
    "            print(\n",
    "                f\"[Epoch {epoch}] \"\n",
    "                f\"Train Loss={tr_loss:.6f}, Train Acc={tr_acc:.6f} | \"\n",
    "                f\"Val Loss={val_met['loss']:.6f}, Val Acc={val_met['acc']:.6f}, \"\n",
    "                f\"Val F1={val_met['f1']:.6f}\"\n",
    "            )\n",
    "\n",
    "            # Early stopping theo Val F1\n",
    "            if val_met['f1'] > best_f1:\n",
    "                best_f1 = val_met['f1']\n",
    "                best_state = model.state_dict()\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve >= patience:\n",
    "                    print(\"Early stopping.\")\n",
    "                    break\n",
    "\n",
    "        # Load lại best state\n",
    "        if best_state is not None:\n",
    "            model.load_state_dict(best_state)\n",
    "\n",
    "        # ===== Dataset NOISE cho TEST (chỉ test, không train) =====\n",
    "        try:\n",
    "            ds_noise = MultiModalDatasetPT(\n",
    "                benign_graph_dir,\n",
    "                ransomware_graph_dirs_noise,\n",
    "                benign_seq_root=benign_seq_root,\n",
    "                ransomware_seq_root=ransomware_seq_root_noise,\n",
    "                max_seq_len=seq_len\n",
    "            )\n",
    "        except RuntimeError as e:\n",
    "            print(f\"[WARN][NOISE] {e} → skip noise test.\")\n",
    "            return\n",
    "\n",
    "        print(f\"[INFO][NOISE] Found {len(ds_noise)} samples (before splitting)\")\n",
    "\n",
    "        # Lấy index test từ metadata cho NOISE\n",
    "        print(\"[INFO] Build split for NOISE dataset (chỉ dùng test_idx_noise)\")\n",
    "        _, _, test_idx_noise, _ = build_split_indices_from_metadata(\n",
    "            ds_noise, metadata_csv_path\n",
    "        )\n",
    "        if len(test_idx_noise) == 0:\n",
    "            print(\"[ERROR] test_idx_noise rỗng (metadata không có split_KB1='test' cho noise).\")\n",
    "            return\n",
    "\n",
    "        test_loader_noise = DataLoader(\n",
    "            Subset(ds_noise, test_idx_noise),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        # Đánh giá trên 2025 NOISE\n",
    "        test_met_noise = eval_metrics(model, test_loader_noise, cls_crit, device)\n",
    "        print(\n",
    "            f\">>> TEST NOISE (2025 noise, RETRAIN) => \"\n",
    "            f\"Loss={test_met_noise['loss']:.6f}, Acc={test_met_noise['acc']:.6f}, \"\n",
    "            f\"TPR={test_met_noise['tpr']:.6f}, FPR={test_met_noise['fpr']:.6f}, \"\n",
    "            f\"Precision={test_met_noise['precision']:.6f}, \"\n",
    "            f\"Recall={test_met_noise['recall']:.6f}, \"\n",
    "            f\"F1={test_met_noise['f1']:.6f}\"\n",
    "        )\n",
    "\n",
    "        # ===== PSI DRIFT: YEAR (2021 vs 2025, CLEAN ransomware-only) =====\n",
    "        drift_stats = report_year_drift_psi_ransom_only(\n",
    "            model, ds_clean,\n",
    "            tr_idx, val_idx, test_idx_clean,\n",
    "            domain_labels_clean,\n",
    "            device=device,\n",
    "            batch_size=batch_size,\n",
    "            n_bins=10,\n",
    "            bin_strategy_prob=\"quantile\",\n",
    "            bin_strategy_w=\"fixed\",\n",
    "        )\n",
    "        print(\"[DRIFT_STATS]\", drift_stats)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    set_seed(42)\n",
    "    run_gcn_xlstm()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8881433,
     "sourceId": 13936191,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8903298,
     "sourceId": 13966507,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8903309,
     "sourceId": 13966522,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8903442,
     "sourceId": 13966706,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8946739,
     "sourceId": 14055412,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9054961,
     "sourceId": 14198733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9063682,
     "sourceId": 14209804,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9078790,
     "sourceId": 14230879,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 9107165,
     "sourceId": 14270793,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11957.612046,
   "end_time": "2025-12-24T12:21:11.733066",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-24T09:01:54.121020",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
